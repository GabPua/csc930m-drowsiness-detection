{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drowsiness Detection Feature Extraction"
      ],
      "metadata": {
        "id": "OA-bWeePWqpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kj5SLvAB_ty"
      },
      "outputs": [],
      "source": [
        "# Import Modules\n",
        "from imutils import face_utils\n",
        "import dlib\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "_7uzOI2wWvvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "\n",
        "# returns angle between two vectors\n",
        "def angle_of_vectors(a,b):\n",
        "     dotProduct = a[0]*b[0] + a[1]*b[1]\n",
        "     modOfVector1 = math.sqrt( a[0]*a[0] + a[1]*a[1])*math.sqrt(b[0]*b[0] + b[1]*b[1]) \n",
        "     angle = dotProduct/modOfVector1\n",
        "     if abs(angle) > 1.0:\n",
        "         return 0 # avoid domain errors\n",
        "     return math.degrees(math.acos(angle))\n",
        "\n",
        "# returns tuple of centroid coordinates\n",
        "def calculate_centroid(points):\n",
        "    sumx = 0\n",
        "    sumy = 0\n",
        "    for (x,y) in points:\n",
        "        sumx += x\n",
        "        sumy += y  \n",
        "    return (sumx/len(points), sumy/len(points))\n",
        "\n",
        "# code for evaluating pitch angle of the head pose taken from\n",
        "# https://learnopencv.com/head-pose-estimation-using-opencv-and-dlib/,\n",
        "# https://github.com/opencv/opencv/blob/3.1.0/samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/src/Utils.cpp#L189,\n",
        "# and https://docs.opencv.org/3.1.0/dc/d2c/tutorial_real_time_pose.html\n",
        "\n",
        "def rot2euler(rotation):\n",
        "    euler = [0, 0, 0] # roll, pitch, yaw\n",
        "    if rotation[1][0] > 0.998:\n",
        "        euler[0] = 0\n",
        "        euler[1] = np.pi / 2\n",
        "        euler[2] = np.arctan2(rotation[0][2], rotation[2][2])\n",
        "    elif rotation[1][0] < -0.998:\n",
        "        euler[0] = 0\n",
        "        euler[1] = -np.pi / 2\n",
        "        euler[2] = np.arctan2(rotation[0][2], rotation[2][2])\n",
        "    else:\n",
        "        euler[0] = np.arctan2(-rotation[1][2], rotation[1][1])\n",
        "        euler[1] = np.arcsin(rotation[1][0])\n",
        "        euler[2] = np.arctan2(-rotation[2][0], rotation[0][0])\n",
        "    return euler\n",
        "\n",
        "def calculate_pitch(points, size):\n",
        "    #3D model points\n",
        "    model_points = np.array([\n",
        "        (0.0, 0.0, 0.0),             # Nose tip\n",
        "        (0.0, -330.0, -65.0),        # Chin\n",
        "        (-225.0, 170.0, -135.0),     # Right eye outer corner\n",
        "        (225.0, 170.0, -135.0),      # Left eye outer corner\n",
        "        (-150.0, -150.0, -125.0),    # Right mouth outer corner\n",
        "        (150.0, -150.0, -125.0)      # Left mouth outer corner\n",
        "    ])\n",
        "    \n",
        "    focal_length = size[1]\n",
        "    center = (size[1]/2, size[0]/2)\n",
        "    camera_matrix = np.array([\n",
        "        [focal_length, 0, center[0]],\n",
        "        [0, focal_length, center[1]],\n",
        "        [0, 0, 1]], dtype = \"double\"\n",
        "    )\n",
        "    \n",
        "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
        "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
        "\n",
        "    angles = rot2euler(cv2.Rodrigues(rotation_vector)[0])\n",
        "    return angles[1]"
      ],
      "metadata": {
        "id": "HLr2DFFlGfDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "6NlhStijW4OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Landmark Declarations\n",
        "\n",
        "p = \"/content/drive/My Drive/Drowsiness Detection/shape_predictor_68_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(p)\n",
        "(L_start, L_end) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "(R_start, R_end) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "(M_start, M_end) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]"
      ],
      "metadata": {
        "id": "xVL8N6aoHIoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204f0bbc-4164-4a4d-dbbb-aa6d55435278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Feature Extraction on Dataset"
      ],
      "metadata": {
        "id": "4XpaBkJuXEOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Main\n",
        "person = 4\n",
        "mode = 0\n",
        "number = 0\n",
        "sequence = []\n",
        "count = 0\n",
        "cap = cv2.VideoCapture('/content/drive/My Drive/Drowsiness Detection/Dataset/0' + str(person) + '/' + str(mode) + '/' + str(number) + '.mov')\n",
        "\n",
        "while True:\n",
        "    good, image = cap.read()\n",
        "    if not good:\n",
        "        break\n",
        "    if count % 100 == 0:\n",
        "        print(count, 'frames processed for', person, mode, number)\n",
        "    count += 1\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    rects = detector(gray, 0)\n",
        "    \n",
        "    # no face detected\n",
        "    if len(rects) == 0:\n",
        "        temp = np.empty((8,))\n",
        "        temp[:] = np.nan\n",
        "        sequence.append(temp)\n",
        "        continue\n",
        "\n",
        "    for (i, rect) in enumerate(rects):\n",
        "        feature_vector = [] # left eye angle, right eye angle, mouth angle, left pupil, right pupil, head pose pitch\n",
        "\n",
        "        shape = predictor(gray, rect)\n",
        "        shape = face_utils.shape_to_np(shape)\n",
        "        \n",
        "        lefteye = shape[L_start : L_end]\n",
        "        righteye = shape[R_start : R_end]\n",
        "        mouth = shape[M_start : M_end]\n",
        "        centroids = [calculate_centroid(lefteye), calculate_centroid(righteye)]\n",
        "        pupils = []\n",
        "\n",
        "        # Eye Angle (inner corner)\n",
        "        LA = lefteye[1] - lefteye[0]\n",
        "        LB = lefteye[5] - lefteye[0]\n",
        "        RA = righteye[2] - righteye[3]\n",
        "        RB = righteye[4] - righteye[3]\n",
        "\n",
        "        feature_vector.append(angle_of_vectors(LA,LB))\n",
        "        feature_vector.append(angle_of_vectors(RA,RB))\n",
        "        \n",
        "        \n",
        "        # Mouth Angle (average of inner mouth angles)\n",
        "        inner_mouth = mouth[12:]\n",
        "        LMA = inner_mouth[3] - inner_mouth[4]\n",
        "        LMB = inner_mouth[5] - inner_mouth[4]\n",
        "        LM = angle_of_vectors(LMA,LMB)\n",
        "        RMA = inner_mouth[1] - inner_mouth[0]\n",
        "        RMB = inner_mouth[7] - inner_mouth[0]\n",
        "        RM = angle_of_vectors(RMA,RMB) \n",
        "\n",
        "        feature_vector.append((LM + RM) / 2.0)\n",
        "\n",
        "        # Pupil \n",
        "        for eye in [lefteye, righteye]:\n",
        "            xs = [p[0] for p in eye]\n",
        "            ys = [p[1] for p in eye] \n",
        "            start = (min(xs), min(ys))\n",
        "            end = (max(xs), max(ys))\n",
        "\n",
        "            gray_eye = gray[start[1]:end[1],start[0]:end[0]]\n",
        "            rows, cols = gray_eye.shape\n",
        "            gray_eye = cv2.GaussianBlur(gray_eye, (11, 11), 0)\n",
        "            gray_eye = cv2.medianBlur(gray_eye, 3)\n",
        "\n",
        "            threshold = cv2.threshold(gray_eye, 127, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "            contours, _ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
        "\n",
        "            for cnt in contours:\n",
        "                (x, y, w, h) = cv2.boundingRect(cnt)\n",
        "                px = x + w/2 + start[0]\n",
        "                py = y + h/2 + start[1]\n",
        "                pupils.append((px,py))\n",
        "                cv2.circle(image, (int(px), int(py)), 2, (255, 0, 0), 2)\n",
        "                break\n",
        "        # left pupil\n",
        "        feature_vector.append(pupils[0][0] - centroids[0][0])\n",
        "        feature_vector.append(pupils[0][1] - centroids[0][1])\n",
        "        # right pupil\n",
        "        if len(pupils) < 2:\n",
        "            feature_vector.append(np.nan)\n",
        "            feature_vector.append(np.nan)\n",
        "        else:\n",
        "            feature_vector.append(pupils[1][0] - centroids[1][0])\n",
        "            feature_vector.append(pupils[1][1] - centroids[1][1])\n",
        "\n",
        "        # Head Pitch Angle\n",
        "        image_points = np.array([\n",
        "            tuple(shape[33]),          # Nose tip\n",
        "            tuple(shape[8]),           # Chin\n",
        "            tuple(righteye[0]),        # Right eye outer corner\n",
        "            tuple(lefteye[3]),         # Left eye outer corner\n",
        "            tuple(mouth[0]),           # Right mouth outer corner\n",
        "            tuple(mouth[6])            # Left mouth outer corner\n",
        "        ], dtype=\"double\")\n",
        "\n",
        "        feature_vector.append(calculate_pitch(image_points, gray.shape))\n",
        "\n",
        "        sequence.append(feature_vector)\n",
        "        # print(feature_vector)\n",
        "        break\n",
        "\n",
        "    # cv2_imshow(image)\n",
        "\n",
        "# save extracted features to csv\n",
        "sequence = np.array(sequence)\n",
        "print(sequence.shape)\n",
        "np.savetxt(str(person) + '_' + str(mode) + '_' + str(number) + \".csv\", sequence, delimiter=\",\")\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6-2o1SuGTGV",
        "outputId": "f8d708ae-d4d3-4023-b5ba-5913f0a1688e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 frames processed for 4 0 0\n",
            "100 frames processed for 4 0 0\n",
            "200 frames processed for 4 0 0\n",
            "300 frames processed for 4 0 0\n",
            "400 frames processed for 4 0 0\n",
            "500 frames processed for 4 0 0\n",
            "600 frames processed for 4 0 0\n",
            "700 frames processed for 4 0 0\n",
            "800 frames processed for 4 0 0\n",
            "900 frames processed for 4 0 0\n",
            "1000 frames processed for 4 0 0\n",
            "1100 frames processed for 4 0 0\n",
            "1200 frames processed for 4 0 0\n",
            "1300 frames processed for 4 0 0\n",
            "1400 frames processed for 4 0 0\n",
            "1500 frames processed for 4 0 0\n",
            "(1501, 8)\n"
          ]
        }
      ]
    }
  ]
}